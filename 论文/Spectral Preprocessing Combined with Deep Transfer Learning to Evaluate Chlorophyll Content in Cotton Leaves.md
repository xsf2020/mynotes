#传统回归模型
## 1. 偏最小二乘回归 (Partial Least Squares, PLS)

PLS 的精髓在于：它不是简单的线性回归，也不是简单的降维，而是**“带方向的降维”**。

### 数学原理

普通的最小二乘法 (OLS) 在变量太多或变量间高度相关时会“崩溃”（系数变得不稳定）。PLS 借鉴了主成分分析 (PCA) 的思想，但有所不同：

- **PCA (主成分分析)**：只管从自变量 $X$ 中找方差最大的方向（只看 $X$ 内部）。
    
- **PLS**：同时对 $X$ 和 $Y$ 进行分解。它寻找的特征向量（称为**潜在变量 Latent Variables**），必须同时满足两个条件：
    
    1. 能尽可能多地保留 $X$ 中的信息。
        
    2. 与 $Y$ 的相关性达到最大。
        

### 工作流程

1. **提取成分**：从原始变量 $X$ 中线性组合出第 1 个潜在变量 $t_1$。
    
2. **建立关联**：计算 $t_1$ 与 $Y$ 的关系。
    
3. **残差更新**：从 $X$ 和 $Y$ 中剔除 $t_1$ 已经解释掉的部分，用剩下的残差继续提取 $t_2$，直到达到预设的主成分个数。
    
4. **重构模型**：最后将所有的潜在变量转换回原始 $X$ 变量的系数。
    

### 核心优势

- **处理多重共线性**：即使变量之间高度相关（如近红外光谱的连续波段），PLS 也能稳定提取信息。
    
- **高维小样本**：当特征数 $p$ 远大于样本数 $n$ 时（例如 1000 个特征，只有 20 个实验样本），PLS 依然有效。
    
- **物理意义**：通过查看变量投影重要性 (VIP) 分数，可以明确知道哪些特征对预测最关键。


## 2. 支持向量机回归 (SVR)

SVR 的精髓在于：它对小的误差“视而不见”，只关注那些“出格”的样本，并能通过“空间跳跃”处理非线性。

### 数学原理

SVR 与传统回归追求“误差平方和最小”不同，它引入了一个**$\epsilon$-不敏感带 (Epsilon-tube)**：

- 如果预测值与真实值的差距在 $\epsilon$ 以内，模型认为没有损失（Loss = 0）。
    
- 只有当预测点掉出这个“管子”时，才计算损失。
    
- **核技巧 (Kernel Trick)**：这是 SVR 的灵魂。它通过核函数（如 RBF 径向基核）将原始数据映射到更高维的空间。在这个高维空间里，原本复杂的非线性关系会变成线性的，从而实现精准拟合。
    

### 工作流程

1. **选择核函数**：根据数据分布选择线性核、多项式核或 RBF 核。
    
2. **训练优化**：寻找一个超平面，使得尽量多的样本点落在 $\epsilon$ 隔离带内，同时保证超平面平滑（防止过拟合）。
    
3. **确定支持向量**：最终模型只由落在边界上或边界外的少数样本（支持向量）决定，大部分带内的点对模型没有贡献。
    

### 核心优势

- **处理非线性**：通过核函数，SVR 能捕捉到 PLS 这种线性模型无法处理的复杂曲线关系。
    
- **鲁棒性**：对异常值不敏感，因为只有部分样本（支持向量）决定模型。
    
- **泛化能力**：由于其追求的是“结构风险最小化”（即模型既要准，又要简单），通常比普通线性回归更不容易过拟合。
![](assets/Spectral%20Preprocessing%20Combined%20with%20Deep%20Transfer%20Learning%20to%20Evaluate%20Chlorophyll%20Content%20in%20Cotton%20Leaves/file-20260122140015183.png)

### 3. 交叉验证指标 (Cross-Validation Metrics)

这组指标是在模型训练阶段，通过你提到的“五折交叉验证”计算出来的，反映了模型的**稳定性**。

- **$R^2_{CV}$ (Cross-Validation R-squared)**：
    
    - **定义**：交叉验证决定系数。
        
    - **意义**：模型在交叉验证中解释变量变异的能力。
        
    - **标准**：越接近 **1** 越好。通常 $R^2_{CV} > 0.5$ 认为模型有意义，$R^2_{CV} > 0.8$ 认为模型非常出色。
        
- **RMSECV (Root Mean Square Error of Cross-Validation)**：
    
    - **定义**：交叉验证均方根误差。
        
    - **意义**：衡量模型在训练过程中的平均偏差。
        
    - **标准**：数值越**小**越好。它与你的原始数据单位一致。如果 RMSECV 远大于训练集的误差，说明模型可能存在过拟合。
        

---

### 4. 外部验证/预测指标 (External Prediction Metrics)

这组指标是使用模型从未见过的新数据（测试集/独立验证集）进行预测得出的，反映了模型的**实战能力**。

- **$R^2_P$ (Prediction R-squared)**：
    
    - **定义**：预测集决定系数。
        
    - **意义**：衡量模型对新样本预测结果的拟合优度。
        
    - **标准**：越接近 **1** 越好。它反映了模型的泛化能力。
        
- **RMSEP (Root Mean Square Error of Prediction)**：
    
    - **定义**：预测均方根误差。
        
    - **意义**：模型在实际预测新样本时的平均误差。
        
    - **标准**：数值越**小**越好。这是衡量模型好坏最关键的指标，因为它代表了你未来使用该模型时的真实精度。

![](assets/Spectral%20Preprocessing%20Combined%20with%20Deep%20Transfer%20Learning%20to%20Evaluate%20Chlorophyll%20Content%20in%20Cotton%20Leaves/file-20260122143840086.png)

#训练集验证集预测集中的R方与RMSE都分别有什么意义?
### 1. 训练集（校准集）指标：$R^2_C$ 和 $RMSEC$

**【对应比喻】：平时的随堂练习、开卷考试。**

- **意义**：衡量模型**“学习能力”**的上限。
    
- **$R^2_C$**：反映模型能多大程度“背下”课本上的知识。如果这个值很低（比如 < 0.7），说明模型太笨或者网络结构太简单，连眼前的这点规律都没抓准（欠拟合）。
    
- **RMSEC**：模型在训练数据上的平均误差。通常它是三个集合中最小的。
    

---

### 2. 验证集指标：$R^2_V$ 和 $RMSEV$

**【对应比喻】：模拟考（用于修正学习策略）。**

- **意义**：衡量模型的**“进化过程”**和**“调参效果”**。
    
- **$R^2_V$**：它是 CNN 训练时的“航标灯”。
    
    - 在深度学习中，你会观察每个 Epoch 的 $R^2_V$。
        
    - **关键点**：如果 $R^2_C$ 很高但 $R^2_V$ 很低，说明模型在“死记硬背”（过拟合）。你会根据这个指标来决定什么时候停止训练，或者要不要加点“Dropout”层。
        
- **RMSEV**：用于判断模型的**稳定性**。我们追求的是 RMSEV 持续下降并趋于平稳。
    

---

### 3. 预测集（测试集）指标：$R^2_P$ 和 $RMSEP$

**【对应比喻】：高考、实战演习。**

- **意义**：衡量模型的**“泛化能力”**和**真实精度**。
    
- **$R^2_P$**：这是论文中最核心的数据。它告诉审稿人：这个模型在面对完全陌生的叶片（从未参与过训练和调参）时，预测结果与真实含量的相关性。
    
    - 比如你提到的 **0.822**，就意味着模型对新样本有 82.2% 的把握。
        
- **RMSEP**：这是用户最关心的指标。如果你把模型封装进 App 或仪器，**RMSEP 就是你给用户的“误差承诺”**（例如：预测结果误差正负不超过 3.472）。
- ![](assets/Spectral%20Preprocessing%20Combined%20with%20Deep%20Transfer%20Learning%20to%20Evaluate%20Chlorophyll%20Content%20in%20Cotton%20Leaves/file-20260122151213766.png)
#微调过程中，目标域的验证集有什么作用 
**目标域的验证集（Validation Set）依然扮演着“教官”和“裁判”的双重角色**。

简单来说，它的核心作用是：**防止模型在新品种的“小样本当中”迷失方向（过拟合），并决定微调何时结束。**

以下是具体的三个关键作用：

---

### 1. 寻找微调的“甜点”（防止过拟合）

由于你微调时只用了目标域校准集的一半（样本量很少），CNN 模型非常容易产生“记忆”效应，即只记住了这几个样本的光谱，而失去了泛化能力。

- **作用**：在微调的每一个 Epoch（迭代周期），模型都会去跑一次目标域的验证集。
    
- **观察点**：如果微调时，训练集的误差在下降，但**验证集的误差开始上升**，这说明模型已经开始过拟合了。
    
- **决策**：此时验证集会触发 **Early Stopping（提前停止）**，强制结束微调，保留模型性能最好的那一刻。
    

---

### 2. 保护“知识迁移”的稳定性

源域模型已经学到了光谱的基础特征（比如哪个波段代表叶绿素）。在微调时，我们希望模型既能学到新品种的特性，又不要忘掉之前学到的基础知识。

- **作用**：验证集能帮你判断微调的**学习率（Learning Rate）**是否合适。
    
- **逻辑**：如果验证集的 $R^2$ 剧烈波动，说明微调步子迈得太大，把预训练学到的好东西都破坏了。你需要根据验证集的表现，把学习率调得更小（通常是预训练时的 $1/10$ 甚至 $1/100$）。
    

---

### 3. 确定最佳的微调策略

微调通常有两种做法：

1. **全量微调**：所有层都重新训练。
    
2. **局部微调**：冻结卷积层，只练全连接层。
    

- **作用**：你究竟该选哪种方案？**验证集是唯一的评价标准。** 你会分别尝试两种方案，看哪一种方案在目标域验证集上的 $R^2_V$ 更高、RMSEV 更小。最后选定的那个方案，才会被拿去跑预测集。